# AI Comment Moderation System

A Python application that detects offensive content in user comments using both local profanity filtering and Groq's LLaMA AI model, with detailed reporting and visualization capabilities.

## Features

- üõ°Ô∏è **Dual-Layer Moderation**:
  - Local profanity filter (`better-profanity`) for fast detection
  - AI analysis via Groq's LLaMA 3 for nuanced classification
- üìä **Comprehensive Reporting**:
  - Offense type breakdown (hate speech, toxicity, etc.)
  - Severity scoring (1-10 scale)
  - Top 5 most severe comments
- üìÅ **Flexible I/O**:
  - Supports CSV/JSON input
  - Exports to CSV, JSON, or both
- üìà **Data Visualization**:
  - Pie/bar charts of offense distribution
- ‚öôÔ∏è **Customizable Thresholds**:
  - Adjustable severity sensitivity

## Requirements

- Python 3.8+
- [Groq API key](https://console.groq.com/)

##  Installation

### Clone the Repository
- ```bash
    https://github.com/krishnavinu/Vyorius-Test.git

## Install dependecy
- ```bash
  pip install -r requirements.txt

## Setup api key
- create .env file
- add this in the file:
  ```bash
  GROQ_API_KEY=your_api_key_here

## Sample input
CSV Format (comments.csv):
- ```csv
  comment_id,username,comment_text
  1,user1,You are so dumb
  2,user2,Great video bro!
  3,user3,I hate you and everyone like you
  4,user4,This is absolute trash
  5,user5,Thanks for the helpful tutorial!
  6,user6,You're a worthless piece of garbage
JSON Format (comments.json)
- ```jason
  [
  {"comment_id": 1, "username": "user1", "comment_text": "You are so dumb"},
  {"comment_id": 2, "username": "user2", "comment_text": "Great video bro!"},
  {"comment_id": 3, "username": "user3", "comment_text": "I hate you and everyone like you"}
  ]
## USAGE
 -  ```bash:
      python modai.py input.json --output-format both --chart-type both  --min-severity 5

- --output-format both [can change between csv or jason]
- --chart-type both [can change between pie or bar]
- --min-severity 5 [adjust from 1-10]
## Samle Output:
- ```bash
       python modai.py input.json --output-format both --chart-type both --min-severity 5
- ```bash 
    Loaded 21 comments from input.json

  Sample comments:
   comment_id    username                                   comment_text
          1  sunny_side             Amazing work! Really enjoyed this.
          2   rageboy77 This is total trash, go learn something first.
          3  happyvibes            Sending you love and good energy! üòä
          4 darkwarrior      This is the dumbest thing I've ever seen.
          5   kindheart      Thank you for sharing this, very helpful!

  Processing comments through moderation system...
  Analyzing comments: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21       [00:20<00:00,  1.00it/s] 

  üíæ Saved CSV results to 'input_analyzed.csv'
  üíæ Saved JSON results to 'input_analyzed.json'

  === MODERATION REPORT ===

  üìä Basic Statistics:
  ‚Ä¢ Total comments processed: 21
  ‚Ä¢ Offensive comments found: 8 (38.1%)

  üîç Offense Type Analysis:
  ‚Ä¢ Profanity: 3 cases
  ‚Ä¢ Toxicity: 2 cases
  ‚Ä¢ Harassment: 2 cases
  ‚Ä¢ Hate_Speech: 1 cases

  ‚ö†Ô∏è Severity Distribution:
  ‚Ä¢ Average severity: 7.1/10
  ‚Ä¢ Maximum severity: 10.0/10
  ‚Ä¢ Minimum severity: 5.0/10
  
  üö® Top 5 Most Severe Comments:
  
  #1 üî• Severity: 10/10
  üë§ User: hateful_mind
  üìù Comment: You are a worthless piece of trash. People like you should be eliminated from society. I hope you suffer.
  üîñ Type: Hate_Speech
  üí¨ Analysis: The comment contains explicit hate speech, advocating for the elimination of a group of people and expressing a desire for harm to be inflicted upon them.        
  
  #2 üî• Severity: 8/10
  üë§ User: toxic123
  üìù Comment: You're so f***ing annoying, go away.
  üîñ Type: Profanity
  üí¨ Analysis: The comment contains profanity and is directed towards an individual, indicating a strong negative sentiment.
  
  #3 üî• Severity: 8/10
  üë§ User: hate_speaker
  üìù Comment: Go die in a hole, nobody cares about your opinion.
  üîñ Type: Harassment
  üí¨ Analysis: The comment contains a direct and aggressive attack on the person, wishing harm and expressing disdain for their opinion.
  
  #4 üî• Severity: 8/10
  üë§ User: mean_girl
  üìù Comment: You're such a loser, nobody likes you.
  üîñ Type: Harassment
  üí¨ Analysis: The comment contains a personal attack and insult, which is considered harassment.
  
  #5 üî• Severity: 6/10
  üë§ User: rageboy77
  üìù Comment: This is total trash, go learn something first.
  üîñ Type: Toxicity
  üí¨ Analysis: The comment contains aggressive language and a condescending tone, which can be perceived as toxic.
  
  üìà Saved pie chart as 'offense_types_pie.png'
  üìä Saved bar chart as 'offense_types_bar.png'
  
## Output file
- input_analyzed.csv
- input_analyzed.jason
  
## Sample Graph
![offense_types_pie](https://github.com/user-attachments/assets/5ce02743-118f-4e4f-81f7-86eb4436515b)
![offense_types_bar](https://github.com/user-attachments/assets/116e0cda-cdbd-4279-928e-632899152924)

